<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=39071&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar? | Théo Morales</title>
<meta name="keywords" content="hand-object pose, meta-learning, test-time adaptation, computer vision, group distribution shifts, dexycb, grasping, benchmark">
<meta name="description" content="Computer vision for hand-object pose has real-world potential. We introduce a benchmark for adapting to pose shifts with meta-learning, showing improvements over the baseline.">
<meta name="author" content="Théo Morales,&amp;thinsp;Gerard Lacey">
<link rel="canonical" href="http://localhost:39071/2/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f862e423d584dcad80ec00d158460a9f311e7d075e2f9c146af7e938d6cf0d7b.css" integrity="sha256-&#43;GLkI9WE3K2A7ADRWEYKnzEefQdeL5wUavfpONbPDXs=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:39071/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:39071/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:39071/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:39071/apple-touch-icon.png">

<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:39071/2/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?" />
<meta property="og:description" content="Computer vision for hand-object pose has real-world potential. We introduce a benchmark for adapting to pose shifts with meta-learning, showing improvements over the baseline." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:39071/2/" /><meta property="article:section" content="publications" />
<meta property="article:published_time" content="2022-10-31T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-10-31T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?"/>
<meta name="twitter:description" content="Computer vision for hand-object pose has real-world potential. We introduce a benchmark for adapting to pose shifts with meta-learning, showing improvements over the baseline."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Publications",
      "item": "http://localhost:39071/publications/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?",
      "item": "http://localhost:39071/2/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?",
  "name": "A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?",
  "description": "Computer vision for hand-object pose has real-world potential. We introduce a benchmark for adapting to pose shifts with meta-learning, showing improvements over the baseline.",
  "keywords": [
    "hand-object pose", "meta-learning", "test-time adaptation", "computer vision", "group distribution shifts", "dexycb", "grasping", "benchmark"
  ],
  "articleBody": " Download Paper Code and data Poster Abstract Understanding hand-object pose with computer vision opens the door to new applications in mixed reality, assisted living or human-robot interaction. Most methods are trained and evaluated on balanced datasets. This is of limited use in real-world applications; how do these methods perform in the wild on unknown objects? We propose a novel benchmark for object group distribution shifts in hand and object pose regression. We then test the hypothesis that meta-learning a baseline pose regression neural network can adapt to these shifts and generalize better to unknown objects. Our results show measurable improvements over the baseline, depending on the amount of prior knowledge. For the task of joint hand-object pose regression, we observe optimization interference for the meta-learner. To address this issue and improve the method further, we provide a comprehensive analysis which should serve as a basis for future work on this benchmark.\nCitation Morales, Théo et al. “A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?” Workshop on Distribution Shifts, 36th Conference on Neural Information Processing Systems (NeurIPS 2022) (2022): 1-8.\n@inproceedings{morales2022a, title={A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?}, author={Th{\\'e}o Morales and Gerard Lacey}, booktitle={NeurIPS 2022 Workshop on Distribution Shifts: Connecting Methods and Applications}, year={2022}, url={https://openreview.net/forum?id=IKbA3QS7c8X} } Related material OpenReview ",
  "wordCount" : "231",
  "inLanguage": "en",
  "datePublished": "2022-10-31T00:00:00Z",
  "dateModified": "2022-10-31T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Théo Morales"
  }, {
    "@type": "Person",
    "name": "Gerard Lacey"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:39071/2/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Théo Morales",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:39071/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:39071/" accesskey="h" title="Théo Morales">
             
                <img src="http://localhost:39071/favicon.png" alt="" aria-label="logo"
                    height="18"
                    width="18">Théo Morales</a>
            <div class="logo-switches">
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:39071/publications/" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:39071/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://notes.theomorales.com" title="Blog">
                    <span>Blog</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?
    </h1>

    
    <div class="post-meta">&lt;span title=&#39;2022-10-31 00:00:00 &#43;0000 UTC&#39;&gt;October 2022&lt;/span&gt;&amp;nbsp;&amp;middot;&amp;nbsp;Théo Morales,&amp;amp;thinsp;Gerard Lacey&nbsp;&middot;&nbsp;<a href="https://doi.org/10.48550/arXiv.2211.00110" rel="noopener noreferrer" target="_blank">Workshop on Distribution Shifts, 36th Conference on Neural Information Processing Systems (NeurIPS 2022)</a>

</div>
  </header> 
  <div class="post-content"><hr>
<h5 id="download">Download</h5>
<ul>
<li><a href="/2.pdf">Paper</a>
</li>
<li><a href="https://github.com/DubiousCactus/meta-learning-HOPE" target="_blank">Code and data</a>
</li>
<li><a href="/2p.pdf">Poster</a>
</li>
</ul>
<hr>
<h5 id="abstract">Abstract</h5>
<p>Understanding hand-object pose with computer vision opens the door to new applications in mixed reality, assisted living or human-robot interaction. Most methods are trained and evaluated on balanced datasets. This is of limited use in real-world applications; how do these methods perform in the wild on unknown objects? We propose a novel benchmark for object group distribution shifts in hand and object pose regression. We then test the hypothesis that meta-learning a baseline pose regression neural network can adapt to these shifts and generalize better to unknown objects. Our results show measurable improvements over the baseline, depending on the amount of prior knowledge. For the task of joint hand-object pose regression, we observe optimization interference for the meta-learner. To address this issue and improve the method further, we provide a comprehensive analysis which should serve as a basis for future work on this benchmark.</p>
<hr>
<h5 id="citation">Citation</h5>
<p>Morales, Théo et al. “A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?” <em>Workshop on Distribution Shifts, 36th Conference on Neural Information Processing Systems (NeurIPS 2022) (2022)</em>: 1-8.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-BibTeX" data-lang="BibTeX"><span style="display:flex;"><span><span style="color:#0a0;text-decoration:underline">@inproceedings</span>{morales2022a,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">title</span>=<span style="color:#a50">{A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">author</span>=<span style="color:#a50">{Th{\&#39;e}o Morales and Gerard Lacey}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">booktitle</span>=<span style="color:#a50">{NeurIPS 2022 Workshop on Distribution Shifts: Connecting Methods and Applications}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">year</span>=<span style="color:#a50">{2022}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">url</span>=<span style="color:#a50">{https://openreview.net/forum?id=IKbA3QS7c8X}</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><hr>
<h5 id="related-material">Related material</h5>
<!--+ [Presentation video](https://www.youtube.com/watch?v=YrR-pR9nDT0)-->
<ul>
<li><a href="https://openreview.net/forum?id=IKbA3QS7c8X" target="_blank">OpenReview</a>
</li>
</ul>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:39071/tags/hand-object-pose/">Hand-Object Pose</a></li>
      <li><a href="http://localhost:39071/tags/meta-learning/">Meta-Learning</a></li>
      <li><a href="http://localhost:39071/tags/test-time-adaptation/">Test-Time Adaptation</a></li>
      <li><a href="http://localhost:39071/tags/computer-vision/">Computer Vision</a></li>
      <li><a href="http://localhost:39071/tags/group-distribution-shifts/">Group Distribution Shifts</a></li>
      <li><a href="http://localhost:39071/tags/dexycb/">Dexycb</a></li>
      <li><a href="http://localhost:39071/tags/grasping/">Grasping</a></li>
      <li><a href="http://localhost:39071/tags/benchmark/">Benchmark</a></li>
    </ul>
  </footer>
</article>
    </main>
    

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
