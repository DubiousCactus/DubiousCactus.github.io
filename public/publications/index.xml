<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Publications on Théo Morales</title>
    <link>https://www.theomorales.com/publications/</link>
    <description>Recent content in Publications on Théo Morales</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 28 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://www.theomorales.com/publications/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Versatile and Differentiable Hand-Object Interaction Representation</title>
      <link>https://www.theomorales.com/CHOIR-WACV/</link>
      <pubDate>Thu, 28 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>https://www.theomorales.com/CHOIR-WACV/</guid>
      <description>CHOIR is a differentiable representation for hand-object interaction. We demonstrate the representation’s usefulness on various tasks, including denoising and synthesis of hand-object interaction.</description>
    </item>
    
    <item>
      <title>ODIN: An OmniDirectional INdoor Dataset Capturing Activities of Daily Living From Multiple Synchronized Modalities</title>
      <link>https://www.theomorales.com/ODIN/</link>
      <pubDate>Sat, 10 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.theomorales.com/ODIN/</guid>
      <description>We present ODIN, a large-scale multi-modal dataset for human behavior understanding using top-view omnidirectional cameras.</description>
    </item>
    
    <item>
      <title>A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?</title>
      <link>https://www.theomorales.com/meta-learning-HOPE/</link>
      <pubDate>Mon, 31 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.theomorales.com/meta-learning-HOPE/</guid>
      <description>Computer vision for hand-object pose has real-world potential. We introduce a benchmark for adapting to pose shifts with meta-learning, showing improvements over the baseline.</description>
    </item>
    
    <item>
      <title>Image generation for efficient neural network training in autonomous drone racing</title>
      <link>https://www.theomorales.com/autonomous-drone-racing/</link>
      <pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.theomorales.com/autonomous-drone-racing/</guid>
      <description>This work proposes a semi-synthetic dataset combining real backgrounds and 3D renders for training convolutional neural networks for drone racing gate detection.</description>
    </item>
    
  </channel>
</rss>
